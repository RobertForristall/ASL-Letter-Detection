{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6213d9b8",
   "metadata": {},
   "source": [
    "# Create and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ae47d",
   "metadata": {},
   "source": [
    "## Create Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26412f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import ascii_uppercase\n",
    "\n",
    "custom_model_name = 'ASL_prototype_labeling'\n",
    "pretrained_model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "pretrained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "tf_record_script_name = 'generate_tfrecord.py'\n",
    "label_map_name = 'ASL_label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'workspace': os.path.join('ASL_AI'),\n",
    "    'scripts': os.path.join('tensorflow', 'scripts'),\n",
    "    'apimodel_path': os.path.join('tensorflow', 'models'),\n",
    "    'annotation_path': os.path.join('ASL_AI', 'annotations'),\n",
    "    'image_path': os.path.join('Images', 'Captured_ASL'),\n",
    "    'model_path': os.path.join('ASL_AI', 'models'),\n",
    "    'pretrained_model_path': os.path.join('tensorflow', 'workspace', 'pre-trained-models'),\n",
    "    'checkpoint_path': os.path.join('ASL_AI', 'models', custom_model_name),\n",
    "    'output_path': os.path.join('ASL_AI', 'models', custom_model_name, 'export'),\n",
    "    'protoc_path': os.path.join('tensorflow', 'protoc')\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'pipeline_config': os.path.join('ASL_AI', 'models', custom_model_name, 'pipeline.config'),\n",
    "    'tf_record_script': os.path.join(paths['scripts'], tf_record_script_name),\n",
    "    'label_map': os.path.join(paths['annotation_path'], label_map_name)\n",
    "}\n",
    "\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ac319",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fde63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 20518283 / 20518283        1 file(s) moved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !wget {pretrained_model_url}\n",
    "    !mv {pretrained_model_name+'.tar.gz'} {paths['pretrained_model_path']}\n",
    "    !cd {paths['pretrained_model_path']} && tar -zxvf {pretrained_model_name+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    import wget\n",
    "    wget.download(pretrained_model_url)\n",
    "    !move {pretrained_model_name+'.tar.gz'} {paths['pretrained_model_path']}\n",
    "    !cd {paths['pretrained_model_path']} && tar -zxvf {pretrained_model_name+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbc051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'ASL_A', 'id': 1}, {'name': 'ASL_B', 'id': 2}, {'name': 'ASL_C', 'id': 3}, {'name': 'ASL_D', 'id': 4}, {'name': 'ASL_E', 'id': 5}, {'name': 'ASL_F', 'id': 6}, {'name': 'ASL_G', 'id': 7}, {'name': 'ASL_H', 'id': 8}, {'name': 'ASL_I', 'id': 9}, {'name': 'ASL_J', 'id': 10}, {'name': 'ASL_K', 'id': 11}, {'name': 'ASL_L', 'id': 12}, {'name': 'ASL_M', 'id': 13}, {'name': 'ASL_N', 'id': 14}, {'name': 'ASL_O', 'id': 15}, {'name': 'ASL_P', 'id': 16}, {'name': 'ASL_Q', 'id': 17}, {'name': 'ASL_R', 'id': 18}, {'name': 'ASL_S', 'id': 19}, {'name': 'ASL_T', 'id': 20}, {'name': 'ASL_U', 'id': 21}, {'name': 'ASL_V', 'id': 22}, {'name': 'ASL_W', 'id': 23}, {'name': 'ASL_X', 'id': 24}, {'name': 'ASL_Y', 'id': 25}, {'name': 'ASL_Z', 'id': 26}]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "counter = 1\n",
    "for char in ascii_uppercase:\n",
    "    labels.append({'name': 'ASL_'+char, 'id': counter})\n",
    "    counter += 1\n",
    "print(labels)\n",
    "\n",
    "#labels = [\n",
    "#    {'name': 'ASL_A', 'id': 1},\n",
    "#    {'name': 'ASL_B', 'id': 2}\n",
    "#]\n",
    "\n",
    "with open(files['label_map'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write(f'\\tname:\\'{label[\"name\"]}\\'\\n')\n",
    "        f.write(f'\\tid:{label[\"id\"]}\\n')\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa0ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\train.record\n",
      "Successfully created the TFRecord file: C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\test.record\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['tf_record_script']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "\n",
    "!python C:\\Users\\redth\\Desktop\\ODT\\tensorflow\\scripts\\generate_tfrecord.py -x C:\\Users\\redth\\Desktop\\ODT\\Images\\Captured_ASL\\train -l C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\ASL_label_map.pbtxt -o C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\train.record \n",
    "!python C:\\Users\\redth\\Desktop\\ODT\\tensorflow\\scripts\\generate_tfrecord.py -x C:\\Users\\redth\\Desktop\\ODT\\Images\\Captured_ASL\\test -l C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\ASL_label_map.pbtxt -o C:\\Users\\redth\\Desktop\\ODT\\ASL_AI\\annotations\\test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9aabd7",
   "metadata": {},
   "source": [
    "## Update model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f1c7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "if os.name == 'posix':\n",
    "    !cp {os.path.join(paths['pretrained_model_path'], pretrained_model_name, 'pipeline.config')} {os.path.join(paths['checkpoint_path'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['pretrained_model_path'], pretrained_model_name, 'pipeline.config')} {os.path.join(paths['checkpoint_path'])}\n",
    "    \n",
    "config = config_util.get_configs_from_pipeline_file(files['pipeline_config'])\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['pipeline_config'], 'r') as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config.model.ssd.num_classes = 26\n",
    "pipeline_config.train_config.batch_size = 16\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['pretrained_model_path'], pretrained_model_name, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files['label_map']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['annotation_path'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['label_map']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['annotation_path'], 'test.record')]\n",
    "\n",
    "pipeline_config.eval_config.num_visualizations = 100\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['pipeline_config'], 'wb') as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24355741",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "command: python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=ASL_AI\\models\\ASL_prototype_labeling --pipeline_config_path=ASL_AI\\models\\ASL_prototype_labeling\\pipeline.config --num_train_steps=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122322e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=ASL_AI\\models\\ASL_prototype_labeling --pipeline_config_path=ASL_AI\\models\\ASL_prototype_labeling\\pipeline.config --num_train_steps=3000\n"
     ]
    }
   ],
   "source": [
    "training_script = os.path.join(paths['apimodel_path'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = f\"python {training_script} --model_dir={paths['checkpoint_path']} --pipeline_config_path={files['pipeline_config']} --num_train_steps=3000\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e2c32",
   "metadata": {},
   "source": [
    "## Eval Model\n",
    "\n",
    "command: python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=ASL_AI\\models\\ASL_prototype_labeling --pipeline_config_path=ASL_AI\\models\\ASL_prototype_labeling\\pipeline.config --checkpoint_dir=ASL_AI\\models\\ASL_prototype_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee86c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=ASL_AI\\models\\ASL_prototype_labeling --pipeline_config_path=ASL_AI\\models\\ASL_prototype_labeling\\pipeline.config --checkpoint_dir=ASL_AI\\models\\ASL_prototype_labeling\n"
     ]
    }
   ],
   "source": [
    "command = f\"python {training_script} --model_dir={paths['checkpoint_path']} --pipeline_config_path={files['pipeline_config']} --checkpoint_dir={paths['checkpoint_path']}\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb3116",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "- Train: cd ASL_AI/models/ASL_prototype_labeling/train && tensorboard --logdir .\n",
    "- Eval: cd ASL_AI/models/ASL_prototype_labeling/eval && tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbc80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
